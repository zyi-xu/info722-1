{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/10 12:23:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('missing').getOrCreate()\n",
    "df = spark.read.csv('cleandiabetedata.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/10 12:23:36 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------+---------------+\n",
      "|features                                                                                        |Diabetes_binary|\n",
      "+------------------------------------------------------------------------------------------------+---------------+\n",
      "|[1.0,1.0,1.0,6.164414002968976,0.0,0.0,0.0,0.0,1.0,1.0,0.0,4.0,0.0,6.0,1.0,0.0,12.0,1.0,4.0]    |0              |\n",
      "|[0.0,1.0,1.0,4.898979485566356,1.0,1.0,0.0,1.0,1.0,0.0,0.0,5.0,30.0,30.0,1.0,0.0,7.0,1.0,3.0]   |0              |\n",
      "|[1.0,1.0,1.0,5.291502622129181,1.0,0.0,1.0,0.0,0.0,1.0,0.0,3.0,30.0,30.0,1.0,0.0,8.0,1.0,1.0]   |0              |\n",
      "|(19,[0,2,3,4,7,11,12,13,16,17,18],[1.0,1.0,5.196152422706632,1.0,1.0,5.0,30.0,25.0,8.0,1.0,1.0])|0              |\n",
      "|(19,[2,3,4,7,8,9,11,15,16,17,18],[1.0,5.385164807134504,1.0,1.0,1.0,1.0,3.0,1.0,12.0,1.0,6.0])  |0              |\n",
      "|[0.0,1.0,1.0,4.47213595499958,0.0,0.0,1.0,1.0,1.0,1.0,0.0,5.0,28.0,20.0,0.0,0.0,11.0,1.0,4.0]   |0              |\n",
      "|(19,[1,2,3,6,11,15,16,17,18],[1.0,1.0,5.0990195135927845,1.0,1.0,1.0,7.0,1.0,4.0])              |0              |\n",
      "|(19,[0,2,3,4,7,9,11,14,16,17,18],[1.0,1.0,4.69041575982343,1.0,1.0,1.0,2.0,1.0,13.0,1.0,3.0])   |0              |\n",
      "|(19,[0,2,3,7,8,9,11,13,16,17,18],[1.0,1.0,5.656854249492381,1.0,1.0,1.0,4.0,4.0,9.0,1.0,3.0])   |0              |\n",
      "|(19,[2,3,7,9,11,16,17,18],[1.0,5.830951894845301,1.0,1.0,3.0,3.0,1.0,6.0])                      |0              |\n",
      "|(19,[2,3,8,9,11,12,13,16,17,18],[1.0,4.47213595499958,1.0,1.0,4.0,10.0,6.0,13.0,1.0,2.0])       |0              |\n",
      "|[0.0,1.0,1.0,5.5677643628300215,1.0,0.0,0.0,1.0,1.0,1.0,0.0,3.0,0.0,1.0,0.0,0.0,12.0,1.0,2.0]   |0              |\n",
      "|(19,[2,3,4,11,15,16,17,18],[1.0,5.385164807134504,1.0,4.0,1.0,4.0,1.0,5.0])                     |0              |\n",
      "|(19,[2,3,7,9,11,15,16,17,18],[1.0,4.795831523312719,1.0,1.0,1.0,1.0,1.0,1.0,6.0])               |0              |\n",
      "|[1.0,1.0,1.0,5.830951894845301,1.0,0.0,0.0,1.0,1.0,1.0,0.0,4.0,0.0,30.0,0.0,0.0,8.0,1.0,1.0]    |0              |\n",
      "|(19,[0,2,3,4,7,8,9,11,16,17,18],[1.0,1.0,5.196152422706632,1.0,1.0,1.0,1.0,3.0,8.0,1.0,8.0])    |0              |\n",
      "|(19,[2,3,4,8,9,10,11,15,16,17,18],[1.0,4.898979485566356,1.0,1.0,1.0,1.0,3.0,1.0,12.0,1.0,4.0]) |0              |\n",
      "|(19,[1,2,3,7,8,9,11,15,16,17,18],[1.0,1.0,5.0990195135927845,1.0,1.0,1.0,3.0,1.0,11.0,1.0,3.0]) |0              |\n",
      "|[1.0,1.0,1.0,5.385164807134504,1.0,0.0,1.0,1.0,1.0,0.0,0.0,4.0,10.0,29.0,0.0,0.0,9.0,1.0,3.0]   |0              |\n",
      "|[0.0,1.0,1.0,5.0990195135927845,0.0,0.0,0.0,1.0,1.0,0.0,0.0,5.0,15.0,15.0,1.0,1.0,9.0,1.0,1.0]  |0              |\n",
      "+------------------------------------------------------------------------------------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train 49516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of test 21171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"HighBP\", \"HighChol\", \"CholCheck\", \"BMI\", \"Smoker\", \"Stroke\", \"HeartDiseaseorAttack\", \"PhysActivity\", \"Fruits\"\\\n",
    "              , \"Veggies\", \"HvyAlcoholConsump\", \"GenHlth\", \"MentHlth\", \"PhysHlth\", \"DiffWalk\", \"Sex\", \"Age\", \"Education\", \"Income\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(df)\n",
    "output.select(\"features\", \"Diabetes_binary\").show(truncate=False)\n",
    "df1=output.select(\"features\", \"Diabetes_binary\")\n",
    "train_df1, test_df1 = df1.randomSplit([0.8, 0.2])\n",
    "\n",
    "print (\"num of train\",train_df1.cache().count())\n",
    "print (\"num of test\",test_df1.cache().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+--------------------+\n",
      "|predictedLabel|Diabetes_binary|            features|\n",
      "+--------------+---------------+--------------------+\n",
      "|             1|              1|(19,[0,1,2,3,4,5,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,5,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,5,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,5,...|\n",
      "|             1|              0|(19,[0,1,2,3,4,5,...|\n",
      "|             1|              0|(19,[0,1,2,3,4,5,...|\n",
      "|             1|              0|(19,[0,1,2,3,4,5,...|\n",
      "|             1|              0|(19,[0,1,2,3,4,5,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              0|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "|             0|              0|(19,[0,1,2,3,4,6,...|\n",
      "|             1|              1|(19,[0,1,2,3,4,6,...|\n",
      "+--------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IndexToString,StringIndexer,VectorIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassificationModel,DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "labelIndexer = StringIndexer().setInputCol(\"Diabetes_binary\").setOutputCol(\"indexedLabel\").fit(df1)\n",
    "featureIndexer = VectorIndexer().setInputCol(\"features\").setOutputCol(\"indexedFeatures\").setMaxCategories(19).fit(df1)\n",
    "labelConverter = IndexToString().setInputCol(\"prediction\").setOutputCol(\"predictedLabel\").setLabels(labelIndexer.labels)\n",
    "\n",
    "dtClassifier = DecisionTreeClassifier(impurity='gini', maxDepth=5, maxBins=32).setLabelCol(\"indexedLabel\").setFeaturesCol(\"indexedFeatures\")\n",
    "pipelinedClassifier = Pipeline().setStages([labelIndexer, featureIndexer, dtClassifier, labelConverter])\n",
    "modelClassifier = pipelinedClassifier.fit(train_df1)\n",
    "predictionsClassifier = modelClassifier.transform(test_df1)\n",
    "predictionsClassifier.select(\"predictedLabel\", \"Diabetes_binary\", \"features\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7186245335600586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 28:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluatorClassifier = MulticlassClassificationEvaluator().setLabelCol(\"indexedLabel\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    " \n",
    "accuracy = evaluatorClassifier.evaluate(predictionsClassifier)\n",
    " \n",
    "print(\"Accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned classification tree model:\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_0ddbd0cdfdea, depth=5, numNodes=35, numClasses=2, numFeatures=19\n",
      "  If (feature 0 in {1.0})\n",
      "   If (feature 3 <= 5.522494968940841)\n",
      "    If (feature 11 in {0.0,2.0,3.0,4.0})\n",
      "     If (feature 1 in {0.0})\n",
      "      If (feature 11 in {3.0,4.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 11 not in {3.0,4.0})\n",
      "       Predict: 1.0\n",
      "     Else (feature 1 not in {0.0})\n",
      "      Predict: 0.0\n",
      "    Else (feature 11 not in {0.0,2.0,3.0,4.0})\n",
      "     If (feature 16 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 16 not in {0.0,1.0,2.0,3.0,4.0,5.0,6.0})\n",
      "      If (feature 18 in {0.0,1.0,2.0,3.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 18 not in {0.0,1.0,2.0,3.0})\n",
      "       Predict: 1.0\n",
      "   Else (feature 3 > 5.522494968940841)\n",
      "    Predict: 0.0\n",
      "  Else (feature 0 not in {1.0})\n",
      "   If (feature 11 in {2.0,3.0,4.0})\n",
      "    If (feature 1 in {1.0})\n",
      "     If (feature 3 <= 5.243827522417907)\n",
      "      If (feature 11 in {3.0,4.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 11 not in {3.0,4.0})\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 5.243827522417907)\n",
      "      Predict: 0.0\n",
      "    Else (feature 1 not in {1.0})\n",
      "     If (feature 3 <= 5.522494968940841)\n",
      "      If (feature 6 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 6 not in {1.0})\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 5.522494968940841)\n",
      "      If (feature 16 in {0.0,8.0,9.0,10.0,11.0,12.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 16 not in {0.0,8.0,9.0,10.0,11.0,12.0})\n",
      "       Predict: 1.0\n",
      "   Else (feature 11 not in {2.0,3.0,4.0})\n",
      "    If (feature 3 <= 5.243827522417907)\n",
      "     Predict: 1.0\n",
      "    Else (feature 3 > 5.243827522417907)\n",
      "     If (feature 11 in {0.0})\n",
      "      If (feature 6 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 6 not in {1.0})\n",
      "       Predict: 1.0\n",
      "     Else (feature 11 not in {0.0})\n",
      "      Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treeModelClassifier = modelClassifier.stages[2]\n",
    " \n",
    "print(\"Learned classification tree model:\\n\" + str(treeModelClassifier.toDebugString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydotplus\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ],
     "output_type": "error"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
